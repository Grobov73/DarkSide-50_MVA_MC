{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code for blur $^{39}Ar$ Monte Carlo parameters\n",
    "# Код для размытия Монте Карло данных $^{39}Ar$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries\n",
    "### Подключаем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import uproot\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pylab as plt\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "import math\n",
    "from scipy.special import gamma\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import numpy.random as ra\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "import cellbell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets \n",
    "### Импортируем наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_Ar39_1 = pd.read_csv('/home/kingaa/Desktop/DarkSide/Monte/data/outputAr39_100kevents.csv',header = 0, sep = \",\")\n",
    "ds_Ar39_2 = pd.read_csv('/home/kingaa/Desktop/DarkSide/Monte/data/outputAr39_100k_events_071019.csv',header = 0, sep = \",\")\n",
    "ds_Ar39_3 = pd.read_csv('/home/kingaa/Desktop/DarkSide/Monte/data/outputAr39_100k_events_211019.csv',header = 0, sep = \",\")\n",
    "ds_Ar39_4 = pd.read_csv('/home/kingaa/Desktop/DarkSide/Monte/data/outputAr39_20kevents_1.csv',header = 0, sep = \",\")\n",
    "ds_Ar39_5 = pd.read_csv('/home/kingaa/Desktop/DarkSide/Monte/data/outputAr39_20kevents_2.csv',header = 0, sep = \",\")\n",
    "ds_Ar39_6 = pd.read_csv('/home/kingaa/Desktop/DarkSide/Monte/data/outputAr39_20kevents_3.csv',header = 0, sep = \",\")\n",
    "\n",
    "ds_Ar39_1 = ds_Ar39_1.dropna()\n",
    "ds_Ar39_2 = ds_Ar39_2.dropna()\n",
    "ds_Ar39_3 = ds_Ar39_3.dropna()\n",
    "ds_Ar39_4 = ds_Ar39_4.dropna()\n",
    "ds_Ar39_5 = ds_Ar39_5.dropna()\n",
    "ds_Ar39_6 = ds_Ar39_6.dropna()\n",
    "\n",
    "ds_Ar39_mall = pd.concat([ds_Ar39_1, ds_Ar39_2, ds_Ar39_3, ds_Ar39_4, ds_Ar39_5, ds_Ar39_6])\n",
    "\n",
    "ds_Ar39 = ds_Ar39_mall\n",
    "\n",
    "ds_Ar39 = ds_Ar39.query('s1>30 and s1 < 500 and f90 > 0.15 and f90 < 0.5')\n",
    "\n",
    "Ar39_f90 = list(ds_Ar39['f90'])\n",
    "Ar39_f30 = list(ds_Ar39['f30'])\n",
    "Ar39_f60 = list(ds_Ar39['f60'])\n",
    "Ar39_f200 = list(ds_Ar39['f200'])\n",
    "Ar39_s1 = list(ds_Ar39['s1'])\n",
    "Ar39_s2 = list(ds_Ar39['s2'])\n",
    "Ar39_late = list(ds_Ar39['s1late'])\n",
    "Ar39_prompt = list(ds_Ar39['s1prompt'])\n",
    "\n",
    "ds_AAr = \"/home/kingaa/Desktop/DarkSide/Monte/AAr_cut_500.root\"\n",
    "tree_AAr = uproot.open(ds_AAr)[\"TreeB\"]\n",
    "\n",
    "df_f90_ds_AAr = tree_AAr.pandas.df('f90')\n",
    "df_f90_ds_AAr['f30'] = tree_AAr.pandas.df('f30')\n",
    "df_f90_ds_AAr['f60'] = tree_AAr.pandas.df('f60')\n",
    "df_f90_ds_AAr['f200'] = tree_AAr.pandas.df('f200')\n",
    "df_f90_ds_AAr['s1'] = tree_AAr.pandas.df('s1')\n",
    "df_f90_ds_AAr['s2'] = tree_AAr.pandas.df('s2')\n",
    "df_f90_ds_AAr['sprompt'] = tree_AAr.pandas.df('long_prompt')\n",
    "df_f90_ds_AAr['slate'] = tree_AAr.pandas.df('long_late')\n",
    "df_f90_ds_AAr = df_f90_ds_AAr.query('s1>30 and s1 < 500 and f90 > 0.15 and f90 < 0.5')\n",
    "\n",
    "AAr_f90 = list(df_f90_ds_AAr['f90'])\n",
    "AAr_f30 = list(df_f90_ds_AAr['f30'])\n",
    "AAr_f60 = list(df_f90_ds_AAr['f60'])\n",
    "AAr_f200 = list(df_f90_ds_AAr['f200'])\n",
    "AAr_s1 = list(df_f90_ds_AAr['s1'])\n",
    "AAr_s2 = list(df_f90_ds_AAr['s2'])\n",
    "AAr_sprompt = list(df_f90_ds_AAr['sprompt'])\n",
    "AAr_slate = list(df_f90_ds_AAr['slate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit functions creation\n",
    "### Создаем фитирующие функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEAP function\n",
    "#### Функция распределения коллаборации DEAP\n",
    "##### DEAP collaboration \"Search for dark matter with a 231-day exposure of liquid argon using DEAP-3600 at SNOLAB\", 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deap_distr_NR(f, a0, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, A):\n",
    "    global q \n",
    "    fbar = a0 + a1/(q - a2) + a3/(q - a4)**2\n",
    "    fbarnew = 1 - fbar\n",
    "    b = a5 + a6/q + a7/q**2\n",
    "    sigma = a8 + a9/q + a10/q**2\n",
    "    fnr = A * 1/math.sqrt(2*math.pi*sigma**2) * np.exp(-(f**2)/(2*sigma**2)) * (fbar**b * (1 - f)**(b-1) * np.exp(-fbar*(1 - f)))/(gamma(b))\n",
    "    return fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### David Hinkley function \n",
    "#### Функция распределения Дэвида Хинкли\n",
    "##### W. H. Lippincott et. al. \"Scintillation time dependence and pulse shape discrimination in liquid argon\", 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinkley(x, mu_s1late_NR, mu_s1prompt_NR, sigma_s1late_NR,sigma_s1prompt_NR, A):\n",
    "    func1 = A * np.exp((-0.5*(mu_s1late_NR*x-mu_s1prompt_NR*(1-x))**2)/(sigma_s1late_NR**2*x**2+sigma_s1prompt_NR**2*(1-x)**2))*(sigma_s1late_NR**2*mu_s1prompt_NR*x+sigma_s1prompt_NR**2*mu_s1late_NR*(1-x))/((2*np.pi)**(0.5)*(sigma_s1late_NR**2*x**2+sigma_s1prompt_NR**2*(1-x)**2)**1.5)\n",
    "    return func1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code for $f_{30}$, $f_{60}$, $f_{90}$, $f_{200}$\n",
    "### Основной код для $f_{30}$, $f_{60}$, $f_{90}$, $f_{200}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform sampling for hinkley distribution\n",
    "# Создаем функцию выборки обратного преобразования\n",
    "def its_hinkley_ER(N):\n",
    "    prob = f_hinkley_ER/float(sum(f_hinkley_ER))\n",
    "    cum_prob = np.cumsum(prob)    \n",
    "    R = ra.uniform(0, 1, N)\n",
    "    gen_random = [float(x_hinkley_ER[np.argwhere(cum_prob == min(cum_prob[(cum_prob - r) > 0]))]) for r in R]  \n",
    "    return gen_random\n",
    "# Blur function for 'extra values' - values that gets into a crowded bin\n",
    "# Создаем функцию размытия для 'экстра значений' - значений, которые попали в переполненный бин\n",
    "def blur(value, depth):\n",
    "    if value == min(list_data):\n",
    "        value = value + 0.001\n",
    "    if value == max(list_data):\n",
    "        value = value - 0.001\n",
    "    j = int(np.argwhere(list_AAr_data[:100] == max(list_AAr_data[:100][(list_AAr_data[:100] - value) <= 0])))\n",
    "    #print(j)\n",
    "    if (n_list_ER[j] < n_AAr_data[j]) or depth == 10:\n",
    "        #print(depth)\n",
    "        return j, value\n",
    "    else:\n",
    "        depth = depth + 1\n",
    "        a = its_hinkley_ER(1)[0]\n",
    "        return blur(a, depth)\n",
    "# Using Hinkley distribution to blur Ar39 parameters (f30, f60, f90, f200)\n",
    "# Используем распределение Хинкли для размытия параметров Ar39 (f30,f60,f90,f200)\n",
    "def hinkley_ER_all(data_AAr):\n",
    "    # Define 'n_AAr_data' - number of events in each bin in AAr data\n",
    "    # Ищем чему равно n в каждом бине в реальных данных NR\n",
    "    global n_AAr_data, list_AAr_data, patches_AAr_data\n",
    "    n_AAr_data, list_AAr_data, patches_AAr_data = plt.hist(data_AAr, bins = 100, density = False)\n",
    "    # Fit\n",
    "    # фитируем\n",
    "    global popt_hinkley_Ar39, pcov_hinkley_Ar39\n",
    "    popt_hinkley_Ar39, pcov_hinkley_Ar39 = curve_fit(hinkley, list_AAr_data[:100], n_AAr_data, maxfev=100000)\n",
    "    print(popt_hinkley_Ar39)\n",
    "    # Calculate n for fit function in each bin\n",
    "    # вычисляем n для фита\n",
    "    global n_f90_AAr_trial_deap\n",
    "    n_f90_AAr_trial_deap = hinkley(list_AAr_data, *popt_hinkley_Ar39)\n",
    "    global x_hinkley_ER,f_hinkley_ER\n",
    "    x_hinkley_ER = np.linspace(min(data), max(data), 200)\n",
    "    f_hinkley_ER = hinkley(x_hinkley_ER, *popt_hinkley_Ar39)\n",
    "    data_blur = []\n",
    "    print(data_blur)\n",
    "    global n_list_ER\n",
    "    n_list_ER = [0] * 101\n",
    "    for i in range (len(data)):\n",
    "        j, value = blur(data[i], 0)\n",
    "        n_list_ER[j] = n_list_ER[j] + 1\n",
    "        data_blur.append(value)\n",
    "    return data_blur, n_list_ER\n",
    "# Function for comparison plotting data before and after blur\n",
    "# Функция для сравнительного построения данных до и после размытия\n",
    "def plotting (AAr_data, Ar39_old, Ar39_new):\n",
    "    nbins = 50\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(121)\n",
    "    n_data_aar, list_data_aar, patches_data_aar = plt.hist(AAr_data, bins = nbins, density = True, histtype = 'step', color = 'black', linewidth = 3, label = 'AAr')\n",
    "    n_data_ar39, list_data_ar39, patches_data_ar39 = plt.hist(Ar39_old, bins = nbins, density = True, histtype = 'step', color = 'red', linewidth = 3, label = 'Ar39')\n",
    "    plt.title('$^{39}$Ar $f_{30}$ до преобразований', fontsize=22)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    n_data_aar, list_data_aar, patches_data_aar = plt.hist(AAr_data, bins = nbins, density = True, histtype = 'step', color = 'black', linewidth = 3, label = 'AAr')\n",
    "    n_new_data_ar39, list_new_data_ar39, patches_new_data_ar39 = plt.hist(Ar39_new, bins = nbins, density = True, histtype = 'step', color = 'red', linewidth = 3, label = 'Ar39')\n",
    "    plt.title('$^{39}$Ar $f_{30}$ после преобразований', fontsize=22)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_AAr_list = ['AAr_f30', 'AAr_f60', 'AAr_f90', 'AAr_f200']\n",
    "Ar39_new_parameters = []\n",
    "for parameter in parameter_AAr_list:\n",
    "    global data\n",
    "    global n_data, list_data, patches_data\n",
    "    shuffled_AAr = random.sample(parameter, len(parameter))\n",
    "    if (parameter == 'AAr_f30'):\n",
    "        data = Ar39_f30\n",
    "    elif (parameter == 'AAr_f60'):\n",
    "        data = Ar39_f60\n",
    "    elif (parameter == 'AAr_f90'):\n",
    "        data = Ar39_f90\n",
    "    elif (parameter == 'AAr_f200'):\n",
    "        data = Ar39_f200\n",
    "    AAr_parameter_lists = []\n",
    "    for i in range (12):\n",
    "        AAr_parameter_lists.append(shuffled_AAr[i*50646:50646*(i+1)])\n",
    "    n_data, list_data, patches_data = plt.hist(data,100)\n",
    "    a = []\n",
    "    lst = []\n",
    "    for i in range (12):\n",
    "        q1,q2 = hinkley_ER_all(AAr_parameter_lists[i])\n",
    "        a.append(q1)\n",
    "        lst.append(q2)\n",
    "    new_param = list(chain(*a))\n",
    "    Ar39_new_parameters.append(new_param)\n",
    "    plotting(parameter, data, new_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code for $S_1$\n",
    "### Основной код для $S_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAr_s1_lists = []\n",
    "for i in range (12):\n",
    "    AAr_s1_lists.append(AAr_s1[i*50646:50646*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAr_f90_trial = list(df_f90_ds_AAr['f90'])[0:50646]\n",
    "AAr_s1_trial = list(df_f90_ds_AAr['s1'])[0:50646]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s1_Ar39, list_s1_Ar39, patches_s1_Ar39 = plt.hist(Ar39_s1, bins = 100, density = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using uniform function for S1 blur, hinkley fit\n",
    "# Используем равномерную функцию распределения для размытия S1, фитируем распределением Хинкли\n",
    "def blur_s1_ER(value, depth):\n",
    "    if value == min(list_s1_Ar39):\n",
    "        value = value + 1\n",
    "    if value == max(list_s1_Ar39):\n",
    "        value = value - 1\n",
    "    j = int(np.argwhere(list_s1_Ar39[:100] == max(list_s1_Ar39[:100][(list_s1_Ar39[:100] - value) <= 0])))\n",
    "    if (n_list_ER_s1[j] < n_s1_AAr_fit[j]) or depth == 5:\n",
    "        return j, value\n",
    "    else:\n",
    "        depth = depth + 1\n",
    "        a = np.random.uniform(min(Ar39_s1),max(Ar39_s1),1)[0]\n",
    "        return blur_s1_ER(a, depth)\n",
    "def hinkley_ER_all_s1(AAr_s1):\n",
    "    # Define 'n_AAr_data' - number of events in each bin in AAr data\n",
    "    # Ищем чему равно n в каждом бине в реальных данных ER\n",
    "    global n_s1_AAr_part, list_s1_AAr_part, patches_s1_AAr_part\n",
    "    n_s1_AAr_part, list_s1_AAr_part, patches_s1_AAr_part = plt.hist(AAr_s1, bins = 100, density = False)\n",
    "    # Fit\n",
    "    # фитируем\n",
    "    popt_hinkley_Ar39, pcov_hinkley_Ar39 = curve_fit(hinkley, list_s1_AAr_part[:100], n_s1_AAr_part, maxfev=100000)\n",
    "    # Calculate n for fit function in each bin\n",
    "    # вычисляем n для фита\n",
    "    global n_s1_AAr_fit\n",
    "    n_s1_AAr_fit = hinkley(list_s1_AAr_part, *popt_hinkley_Ar39)\n",
    "    Ar39_s1_deap = []\n",
    "    global n_list_ER_s1\n",
    "    n_list_ER_s1 = [0] * 201\n",
    "    for i in range (len(Ar39_s1)):\n",
    "        j, value = blur_s1_ER(Ar39_s1[i], 0)\n",
    "        n_list_ER_s1[j] = n_list_ER_s1[j] + 1\n",
    "        Ar39_s1_deap.append(value)\n",
    "    return Ar39_s1_deap, n_list_ER_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "lst = []\n",
    "for i in range (12):\n",
    "    q1,q2 = uniform_ER_all_s1(AAr_s1_lists[i])\n",
    "    a.append(q1)\n",
    "    lst.append(q2)\n",
    "Ar39_s1_deap = list(chain(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame and save it\n",
    "# Создание нового датафрейма и сохранение его в .csv файл\n",
    "data = {'f30':Ar39_new_parameters[0], 'f60':Ar39_new_parameters[1], 'f90':Ar39_new_parameters[2], 'f200':Ar39_new_parameters[3], 's1':Ar39_s1_new}\n",
    "df = pd.DataFrame(data) \n",
    "df.to_csv('new_ds_Ar39_MC_30_500_f30_f60_f90_f200_s1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
